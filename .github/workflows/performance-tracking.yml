name: Performance Tracking

on:
  # Run after CI completes for master branch pushes
  workflow_run:
    workflows: ["CI"]
    types:
      - completed
    branches:
      - master
  # Run weekly on Sundays at 00:00 UTC to track long-term trends
  schedule:
    - cron: '0 0 * * 0'

permissions:
  contents: write

jobs:
  performance-analysis:
    name: Performance Analysis & Trend Detection
    runs-on: ubuntu-latest
    timeout-minutes: 45
    # Only run if CI workflow succeeded or if this is a scheduled run
    if: github.event_name == 'schedule' || github.event.workflow_run.conclusion == 'success'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 24

      - name: Cache Yarn dependencies
        id: yarn-cache
        uses: actions/cache@v4
        with:
          path: .yarn/cache
          key: yarn-${{ hashFiles('**/yarn.lock') }}
          restore-keys: |
            yarn-

      - name: Install dependencies
        run: yarn install --immutable

      - name: Verify cache hit
        if: steps.yarn-cache.outputs.cache-hit != 'true'
        run: echo "::warning::Yarn cache miss, slower install expected"

      - name: Download Test Results from CI (for workflow_run events)
        if: github.event_name == 'workflow_run'
        id: download-ci-results
        uses: actions/download-artifact@v4
        with:
          pattern: playwright-report-*
          path: test-results-raw/
          merge-multiple: true
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}

      - name: Merge Test Results (for workflow_run events)
        if: github.event_name == 'workflow_run'
        run: |
          mkdir -p test-results
          # Copy test-results.json from downloaded artifacts
          if [ -f test-results-raw/test-results.json ]; then
            cp test-results-raw/test-results.json test-results/
          else
            # If not in root, find it in subdirectories
            find test-results-raw -name "test-results.json" -exec cp {} test-results/ \;
          fi

      - name: Cache Playwright Browsers (for scheduled runs only)
        if: github.event_name == 'schedule'
        id: playwright-cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-browsers-${{ hashFiles('**/yarn.lock') }}
          restore-keys: |
            playwright-browsers-

      - name: Install Playwright Browsers (for scheduled runs only)
        if: github.event_name == 'schedule' && steps.playwright-cache.outputs.cache-hit != 'true'
        run: npx playwright install --with-deps

      - name: Install Playwright Browser Dependencies (for scheduled runs only)
        if: github.event_name == 'schedule' && steps.playwright-cache.outputs.cache-hit == 'true'
        run: npx playwright install-deps

      - name: Download Previous Performance Baseline
        id: download-baseline
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: performance-baseline
          path: .performance-baseline/

      - name: Run E2E Tests (scheduled runs only)
        if: github.event_name == 'schedule'
        run: yarn e2e

      - name: Analyze Current Performance
        run: |
          node scripts/analyze-performance.mjs \
            --format console \
            --output test-results/current-performance.json

      - name: Compare with Baseline (if available)
        if: steps.download-baseline.outcome == 'success'
        continue-on-error: true
        run: |
          echo "üìä Comparing with previous baseline..."
          node scripts/analyze-performance.mjs \
            --current test-results/test-results.json \
            --baseline .performance-baseline/baseline.json \
            --threshold 15 \
            --format markdown \
            --output test-results/regression-report.md

      - name: Generate Performance Report
        if: always()
        run: |
          node scripts/analyze-performance.mjs \
            --format markdown \
            --output test-results/performance-report.md

      - name: Save Current Results as Baseline
        run: |
          mkdir -p .performance-baseline
          cp test-results/test-results.json .performance-baseline/baseline.json
          cp test-results/current-performance.json .performance-baseline/performance.json

      - name: Upload Performance Baseline
        uses: actions/upload-artifact@v4
        with:
          name: performance-baseline
          path: .performance-baseline/
          retention-days: 30

      - name: Upload Performance Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-reports-${{ github.run_number }}
          path: test-results/*.json
          retention-days: 30

      - name: Check for Critical Regressions
        if: steps.download-baseline.outcome == 'success' && github.event_name != 'schedule'
        run: |
          echo "üîç Checking for critical performance regressions..."
          node scripts/analyze-performance.mjs \
            --current test-results/test-results.json \
            --baseline .performance-baseline/baseline.json \
            --threshold 25 \
            --fail-on-regression

  performance-dashboard:
    name: Generate Performance Dashboard
    runs-on: ubuntu-latest
    needs: performance-analysis
    timeout-minutes: 20
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 24

      - name: Cache Yarn dependencies
        id: yarn-cache
        uses: actions/cache@v4
        with:
          path: .yarn/cache
          key: yarn-${{ hashFiles('**/yarn.lock') }}
          restore-keys: |
            yarn-

      - name: Install dependencies
        run: yarn install --immutable

      - name: Verify cache hit
        if: steps.yarn-cache.outputs.cache-hit != 'true'
        run: echo "::warning::Yarn cache miss, slower install expected"

      - name: Download All Historical Performance Data
        continue-on-error: true
        run: |
          mkdir -p .performance-history

          # Download recent artifacts (last 30 runs)
          gh run list --workflow=performance-tracking.yml --limit 30 --json databaseId --jq '.[].databaseId' | \
          while read run_id; do
            echo "Downloading artifacts from run $run_id..."
            gh run download $run_id --pattern "performance-reports-*" --dir .performance-history/ || true
          done
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Generate Performance Trends Dashboard
        run: node scripts/generate-performance-dashboard.mjs

      - name: Upload Dashboard
        uses: actions/upload-artifact@v4
        with:
          name: performance-dashboard
          path: performance-dashboard/
          retention-days: 30

      - name: Deploy Dashboard to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./performance-dashboard
          destination_dir: performance
